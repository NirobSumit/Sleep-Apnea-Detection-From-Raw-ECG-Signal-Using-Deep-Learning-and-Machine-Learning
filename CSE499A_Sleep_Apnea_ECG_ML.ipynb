{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a0b7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mat4py import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import sklearn\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization,Concatenate,concatenate, Input\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c78edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_string=['ucddb002','ucddb003','ucddb005','ucddb006','ucddb007','ucddb009',\\\n",
    "             'ucddb010','ucddb012','ucddb014','ucddb015','ucddb017',\\\n",
    "             'ucddb019','ucddb020','ucddb021','ucddb022','ucddb023','ucddb024',\\\n",
    "             'ucddb025','ucddb026','ucddb027','ucddb028']#'ucddb008','ucddb011','ucddb013','ucddb014',\n",
    "\n",
    "\n",
    "valid_features=np.zeros((1,1408))\n",
    "test_features=np.zeros((1,1408))\n",
    "valid_labels=np.zeros((1,1))\n",
    "test_labels=np.zeros((1,1))\n",
    "for l in list_string:\n",
    "        \n",
    "        \n",
    "        ecg_valid = loadmat('D:\\\\CSE499\\\\files2\\\\'+l+'_ecg_valid.mat')\n",
    "        ecg_valid = np.array(ecg_valid['ecg_valid'])\n",
    "        ecg_valid_labels=loadmat('D:\\\\CSE499\\\\files2\\\\'+l+'_valid_labels.mat')\n",
    "        ecg_valid_labels = np.array(ecg_valid_labels['class_valid'])\n",
    "        valid_features=np.append(valid_features,ecg_valid,axis=0)\n",
    "        valid_labels=np.append(valid_labels,ecg_valid_labels)\n",
    "       \n",
    "        \n",
    "        ecg_test = loadmat('D:\\\\CSE499\\\\files2\\\\'+l+'_ecg_test.mat')\n",
    "        ecg_test = np.array(ecg_test['ecg_test'])\n",
    "        ecg_test_labels=loadmat('D:\\\\CSE499\\\\files2\\\\'+l+'_test_labels.mat')\n",
    "        ecg_test_labels = np.array(ecg_test_labels['class_test'])\n",
    "        test_features=np.append(test_features,ecg_test,axis=0)\n",
    "        test_labels=np.append(test_labels,ecg_test_labels)\n",
    "        \n",
    "ecg_valid=valid_features[1:,:]\n",
    "valid_labels=valid_labels[1:]\n",
    "valid_labels = valid_labels.flatten()\n",
    "\n",
    "ecg_test=test_features[1:,:]\n",
    "test_labels=test_labels[1:]\n",
    "test_labels = test_labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02239470",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=np.zeros((1,1408))\n",
    "\n",
    "train_labels=np.zeros((1,1))\n",
    "\n",
    "for l in list_string:\n",
    "        ecg_train = loadmat('D:\\\\CSE499\\\\files2\\\\'+l+'_ecg_train.mat')\n",
    "        ecg_train = np.array(ecg_train['ecg_train'])\n",
    "        ecg_train_labels=loadmat('D:\\\\CSE499\\\\files2\\\\'+l+'_train_labels.mat')\n",
    "        ecg_train_labels = np.array(ecg_train_labels['class_train'])\n",
    "        train_features=np.append(train_features,ecg_train,axis=0)\n",
    "        train_labels=np.append(train_labels,ecg_train_labels)\n",
    "        \n",
    "ecg_train=train_features[1:,:]\n",
    "\n",
    "train_labels=train_labels[1:]\n",
    "train_labels = train_labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f64241",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_train_mean=np.mean(ecg_train)\n",
    "ecg_train_std=np.std(ecg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2bd026",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ecg_train.shape[0]):\n",
    "    ecg_train[i,:]=(ecg_train[i,:]-ecg_train_mean)/ecg_train_std\n",
    "    \n",
    "for i in range(ecg_valid.shape[0]):\n",
    "    ecg_valid[i,:]=(ecg_valid[i,:]-ecg_train_mean)/ecg_train_std\n",
    "    \n",
    "for i in range(ecg_test.shape[0]):\n",
    "    ecg_test[i,:]=(ecg_test[i,:]-ecg_train_mean)/ecg_train_std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a45a8e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_labels\n",
    "y_valid=valid_labels\n",
    "y_test=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6102157",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f6cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "y_train_num = y_train_encoder.fit_transform(y_train)\n",
    "y_train_wide = tensorflow.keras.utils.to_categorical(y_train_num, num_classes)\n",
    "\n",
    "y_valid_num = y_train_encoder.fit_transform(y_valid)\n",
    "y_valid_wide = tensorflow.keras.utils.to_categorical(y_valid_num, num_classes)\n",
    "\n",
    "y_test_num = y_train_encoder.fit_transform(y_test)\n",
    "y_test_wide = tensorflow.keras.utils.to_categorical(y_test_num, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c091a0e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tensorflow.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b1e8d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\CSE299\\Flutter\\Anaconda\\envs\\EEG_Signal\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6571826194526056\n",
      "Logistic Regression Confusion Matrix:\n",
      " [[33501 16867]\n",
      " [  869   499]]\n",
      "Logistic Regression Specificity: 0.6651246823379924\n",
      "Logistic Regression Sensitivity: 0.364766081871345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "logistic_regression_model = LogisticRegression(random_state=42)\n",
    "logistic_regression_model.fit(ecg_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "logistic_regression_predictions = logistic_regression_model.predict(ecg_test)\n",
    "\n",
    "# Evaluate the model\n",
    "logistic_regression_accuracy = accuracy_score(y_test, logistic_regression_predictions)\n",
    "logistic_regression_conf_matrix = confusion_matrix(y_test, logistic_regression_predictions)\n",
    "logistic_regression_specificity = logistic_regression_conf_matrix[0, 0] / (logistic_regression_conf_matrix[0, 0] + logistic_regression_conf_matrix[0, 1])\n",
    "logistic_regression_sensitivity = logistic_regression_conf_matrix[1, 1] / (logistic_regression_conf_matrix[1, 1] + logistic_regression_conf_matrix[1, 0])\n",
    "\n",
    "# Print or use these metrics for Logistic Regression as needed\n",
    "print(\"Logistic Regression Accuracy:\", logistic_regression_accuracy)\n",
    "print(\"Logistic Regression Confusion Matrix:\\n\", logistic_regression_conf_matrix)\n",
    "print(\"Logistic Regression Specificity:\", logistic_regression_specificity)\n",
    "print(\"Logistic Regression Sensitivity:\", logistic_regression_sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0195050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9440814906448122\n",
      "Decision Tree Confusion Matrix:\n",
      " [[48747  1621]\n",
      " [ 1272    96]]\n",
      "Decision Tree Specificity: 0.9678168678526048\n",
      "Decision Tree Sensitivity: 0.07017543859649122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create and train the Decision Tree model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree_model.fit(ecg_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "decision_tree_predictions = decision_tree_model.predict(ecg_test)\n",
    "\n",
    "# Evaluate the model\n",
    "decision_tree_accuracy = accuracy_score(y_test, decision_tree_predictions)\n",
    "decision_tree_conf_matrix = confusion_matrix(y_test, decision_tree_predictions)\n",
    "decision_tree_specificity = decision_tree_conf_matrix[0, 0] / (decision_tree_conf_matrix[0, 0] + decision_tree_conf_matrix[0, 1])\n",
    "decision_tree_sensitivity = decision_tree_conf_matrix[1, 1] / (decision_tree_conf_matrix[1, 1] + decision_tree_conf_matrix[1, 0])\n",
    "\n",
    "# Print or use these metrics for Decision Tree as needed\n",
    "print(\"Decision Tree Accuracy:\", decision_tree_accuracy)\n",
    "print(\"Decision Tree Confusion Matrix:\\n\", decision_tree_conf_matrix)\n",
    "print(\"Decision Tree Specificity:\", decision_tree_specificity)\n",
    "print(\"Decision Tree Sensitivity:\", decision_tree_sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69b4edfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.6210955620844286\n",
      "AdaBoost Confusion Matrix:\n",
      " [[31533 18835]\n",
      " [  768   600]]\n",
      "AdaBoost Specificity: 0.6260522554002541\n",
      "AdaBoost Sensitivity: 0.43859649122807015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Create and train the AdaBoost model\n",
    "adaboost_model = AdaBoostClassifier(random_state=42)\n",
    "adaboost_model.fit(ecg_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "adaboost_predictions = adaboost_model.predict(ecg_test)\n",
    "\n",
    "# Evaluate the model\n",
    "adaboost_accuracy = accuracy_score(y_test, adaboost_predictions)\n",
    "adaboost_conf_matrix = confusion_matrix(y_test, adaboost_predictions)\n",
    "adaboost_specificity = adaboost_conf_matrix[0, 0] / (adaboost_conf_matrix[0, 0] + adaboost_conf_matrix[0, 1])\n",
    "adaboost_sensitivity = adaboost_conf_matrix[1, 1] / (adaboost_conf_matrix[1, 1] + adaboost_conf_matrix[1, 0])\n",
    "\n",
    "# Print or use these metrics for AdaBoost as needed\n",
    "print(\"AdaBoost Accuracy:\", adaboost_accuracy)\n",
    "print(\"AdaBoost Confusion Matrix:\\n\", adaboost_conf_matrix)\n",
    "print(\"AdaBoost Specificity:\", adaboost_specificity)\n",
    "print(\"AdaBoost Sensitivity:\", adaboost_sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61722fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9243853409618061\n",
      "XGBoost Confusion Matrix:\n",
      " [[47624  2744]\n",
      " [ 1168   200]]\n",
      "XGBoost Specificity: 0.9455209656925032\n",
      "XGBoost Sensitivity: 0.14619883040935672\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create and train the XGBoost model\n",
    "xgboost_model = xgb.XGBClassifier(random_state=42)\n",
    "xgboost_model.fit(ecg_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgboost_predictions = xgboost_model.predict(ecg_test)\n",
    "\n",
    "# Evaluate the model\n",
    "xgboost_accuracy = accuracy_score(y_test, xgboost_predictions)\n",
    "xgboost_conf_matrix = confusion_matrix(y_test, xgboost_predictions)\n",
    "xgboost_specificity = xgboost_conf_matrix[0, 0] / (xgboost_conf_matrix[0, 0] + xgboost_conf_matrix[0, 1])\n",
    "xgboost_sensitivity = xgboost_conf_matrix[1, 1] / (xgboost_conf_matrix[1, 1] + xgboost_conf_matrix[1, 0])\n",
    "\n",
    "# Print or use these metrics for XGBoost as needed\n",
    "print(\"XGBoost Accuracy:\", xgboost_accuracy)\n",
    "print(\"XGBoost Confusion Matrix:\\n\", xgboost_conf_matrix)\n",
    "print(\"XGBoost Specificity:\", xgboost_specificity)\n",
    "print(\"XGBoost Sensitivity:\", xgboost_sensitivity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecd8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create and train the Gradient Boosting model\n",
    "gradient_boosting_model = GradientBoostingClassifier(random_state=42)\n",
    "gradient_boosting_model.fit(ecg_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "gradient_boosting_predictions = gradient_boosting_model.predict(ecg_test)\n",
    "\n",
    "# Evaluate the model\n",
    "gradient_boosting_accuracy = accuracy_score(y_test, gradient_boosting_predictions)\n",
    "gradient_boosting_conf_matrix = confusion_matrix(y_test, gradient_boosting_predictions)\n",
    "gradient_boosting_specificity = gradient_boosting_conf_matrix[0, 0] / (gradient_boosting_conf_matrix[0, 0] + gradient_boosting_conf_matrix[0, 1])\n",
    "gradient_boosting_sensitivity = gradient_boosting_conf_matrix[1, 1] / (gradient_boosting_conf_matrix[1, 1] + gradient_boosting_conf_matrix[1, 0])\n",
    "\n",
    "# Print or use these metrics for Gradient Boosting as needed\n",
    "print(\"Gradient Boosting Accuracy:\", gradient_boosting_accuracy)\n",
    "print(\"Gradient Boosting Confusion Matrix:\\n\", gradient_boosting_conf_matrix)\n",
    "print(\"Gradient Boosting Specificity:\", gradient_boosting_specificity)\n",
    "print(\"Gradient Boosting Sensitivity:\", gradient_boosting_sensitivity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
